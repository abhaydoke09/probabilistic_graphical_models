{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections, numpy\n",
    "from numpy import genfromtxt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_names = ['A','G','CP','BP','CH','ECG','HR','EIA','HD']\n",
    "data_name2index = {}\n",
    "for i,val in enumerate(data_names):\n",
    "    data_name2index[val] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_names = ['A','G','CP','BP','CH','ECG','HR','EIA','HD']\n",
    "df = pd.read_csv('../Data/data-train-1.txt', names=data_names,dtype=\"|S5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_CPT(target,all_data_frame,parents=[]):\n",
    "    CPT = {}\n",
    "    if len(parents)==0:\n",
    "        #print target\n",
    "        g = all_data_frame.groupby([target])\n",
    "        #print g.groups\n",
    "        normalizer = all_data_frame.shape[0]\n",
    "        for target_value in g.groups.keys():\n",
    "            #CPT[(target_value)] = lig.groups[target_value]\n",
    "            CPT[(target_value,)] = g.groups[target_value].shape[0]*1.0/normalizer\n",
    "        return CPT\n",
    "    else:\n",
    "        g = all_data_frame.groupby(parents)\n",
    "        data_groups = g.groups.keys()\n",
    "        #print g.groups\n",
    "        for target_value in all_data_frame[target].unique():\n",
    "            #print target_value\n",
    "            for data_group in data_groups:\n",
    "                data = all_data_frame.ix[list(g.groups[data_group])]\n",
    "                cpt_key = list(data_group)\n",
    "                cpt_key.insert(0,target_value)\n",
    "                #print data[data[target]==target_value]\n",
    "                normalizer = data.shape[0]\n",
    "                #print normalizer\n",
    "                #print \"-->\",data[data[target]==target_value].shape[0],\"-->\",normalizer\n",
    "                CPT[tuple(cpt_key)] = data[data[target]==target_value].shape[0]*1.0/normalizer\n",
    "        return CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CPT_table_nales = ['CPT_A', 'CPT_G', 'CPT_CP_HD', 'CPT_BP_G', 'CPT_ECG_HD', 'CPT_HD_BP_CH', 'CPT_CH_G_A', 'CPT_EIA_HD', 'CPT_HR_A_HD']\n",
    "def get_CPT_all(df):\n",
    "    result = {}\n",
    "    result['CPT_A'] = generate_CPT('A',df)\n",
    "    result['CPT_G'] = generate_CPT('G',df)\n",
    "    result['CPT_BP_G'] = generate_CPT('BP',df,['G'])\n",
    "    result['CPT_CH_G_A'] = generate_CPT('CH',df,['G','A'])\n",
    "    result['CPT_HD_BP_CH'] = generate_CPT('HD',df,['BP','CH'])\n",
    "    result['CPT_CP_HD'] = generate_CPT('CP',df,['HD'])\n",
    "    result['CPT_EIA_HD'] = generate_CPT('EIA',df,['HD'])\n",
    "    result['CPT_ECG_HD'] = generate_CPT('ECG',df,['HD'])\n",
    "    result['CPT_HR_A_HD'] = generate_CPT('HR',df,['A','HD'])\n",
    "    #print result.keys()\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPT_A --> {('3',): 0.51440329218107, ('1',): 0.17695473251028807, ('2',): 0.30864197530864196}\n",
      "\n",
      "CPT_G --> {('1',): 0.3374485596707819, ('2',): 0.6625514403292181}\n",
      "\n",
      "CPT_CP_HD --> {('1', '1'): 0.06766917293233082, ('2', '2'): 0.07272727272727272, ('2', '1'): 0.2631578947368421, ('3', '1'): 0.42105263157894735, ('3', '2'): 0.10909090909090909, ('4', '1'): 0.24812030075187969, ('1', '2'): 0.05454545454545454, ('4', '2'): 0.7636363636363637}\n",
      "\n",
      "CPT_BP_G --> {('2', '1'): 0.6341463414634146, ('1', '2'): 0.4720496894409938, ('1', '1'): 0.36585365853658536, ('2', '2'): 0.5279503105590062}\n",
      "\n",
      "CPT_ECG_HD --> {('2', '1'): 0.40601503759398494, ('1', '2'): 0.41818181818181815, ('1', '1'): 0.5939849624060151, ('2', '2'): 0.5818181818181818}\n",
      "\n",
      "CPT_HD_BP_CH --> {('2', '1', '1'): 0.47368421052631576, ('1', '1', '1'): 0.5263157894736842, ('2', '2', '1'): 0.4090909090909091, ('1', '1', '2'): 0.5862068965517241, ('2', '2', '2'): 0.48695652173913045, ('1', '2', '2'): 0.5130434782608696, ('2', '1', '2'): 0.41379310344827586, ('1', '2', '1'): 0.5909090909090909}\n",
      "\n",
      "CPT_CH_G_A --> {('2', '1', '3'): 0.8936170212765957, ('2', '1', '1'): 0.7857142857142857, ('1', '1', '1'): 0.21428571428571427, ('2', '2', '1'): 0.7241379310344828, ('1', '2', '3'): 0.16666666666666666, ('2', '2', '3'): 0.8333333333333334, ('1', '1', '2'): 0.14285714285714285, ('2', '2', '2'): 0.8333333333333334, ('1', '2', '2'): 0.16666666666666666, ('1', '1', '3'): 0.10638297872340426, ('2', '1', '2'): 0.8571428571428571, ('1', '2', '1'): 0.27586206896551724}\n",
      "\n",
      "CPT_EIA_HD --> {('2', '1'): 0.11278195488721804, ('1', '2'): 0.41818181818181815, ('1', '1'): 0.8872180451127819, ('2', '2'): 0.5818181818181818}\n",
      "\n",
      "CPT_HR_A_HD --> {('2', '3', '1'): 0.6666666666666666, ('2', '1', '1'): 0.9393939393939394, ('1', '1', '1'): 0.06060606060606061, ('1', '3', '1'): 0.3333333333333333, ('2', '2', '1'): 0.8269230769230769, ('2', '1', '2'): 0.4, ('1', '1', '2'): 0.6, ('2', '2', '2'): 0.4782608695652174, ('1', '2', '2'): 0.5217391304347826, ('2', '3', '2'): 0.42857142857142855, ('1', '3', '2'): 0.5714285714285714, ('1', '2', '1'): 0.17307692307692307}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CPT_tables = get_CPT_all(df)\n",
    "for table_name in CPT_table_names:\n",
    "    print table_name,'-->',CPT_tables[table_name]\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A) -->  {('3',): 0.51440329218107, ('1',): 0.17695473251028807, ('2',): 0.30864197530864196} \n",
      "\n",
      "P(BP|G) -->  {('2', '1'): 0.6341463414634146, ('1', '2'): 0.4720496894409938, ('1', '1'): 0.36585365853658536, ('2', '2'): 0.5279503105590062} \n",
      "\n",
      "P(HD|BP,CH) -->  {('2', '1', '1'): 0.47368421052631576, ('1', '1', '1'): 0.5263157894736842, ('2', '2', '1'): 0.4090909090909091, ('1', '1', '2'): 0.5862068965517241, ('2', '2', '2'): 0.48695652173913045, ('1', '2', '2'): 0.5130434782608696, ('2', '1', '2'): 0.41379310344827586, ('1', '2', '1'): 0.5909090909090909} \n",
      "\n",
      "P(HR|A,HD) -->  {('2', '3', '1'): 0.6666666666666666, ('2', '1', '1'): 0.9393939393939394, ('1', '1', '1'): 0.06060606060606061, ('1', '3', '1'): 0.3333333333333333, ('2', '2', '1'): 0.8269230769230769, ('2', '1', '2'): 0.4, ('1', '1', '2'): 0.6, ('2', '2', '2'): 0.4782608695652174, ('1', '2', '2'): 0.5217391304347826, ('2', '3', '2'): 0.42857142857142855, ('1', '3', '2'): 0.5714285714285714, ('1', '2', '1'): 0.17307692307692307} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'P(A) --> ',CPT_tables['CPT_A'],'\\n'\n",
    "print 'P(BP|G) --> ',CPT_tables['CPT_BP_G'],'\\n'\n",
    "print 'P(HD|BP,CH) --> ',CPT_tables['CPT_HD_BP_CH'],'\\n'\n",
    "print 'P(HR|A,HD) --> ',CPT_tables['CPT_HR_A_HD'],'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847769028871\n",
      "0.152230971129\n"
     ]
    }
   ],
   "source": [
    "#P(CH|A = 2, G = M, CP = None, BP = L, ECG = Normal, HR = L, EIA = No, HD = No)\n",
    "denominator = CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('1','2','2')]*CPT_HD_BP_CH[('1','1','1')]\\\n",
    "            + CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('2','2','2')]*CPT_HD_BP_CH[('1','1','2')]\n",
    "numerator = CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('2','2','2')]*CPT_HD_BP_CH[('1','1','2')]*1.0\n",
    "print numerator/denominator\n",
    "\n",
    "numerator = CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('1','2','2')]*CPT_HD_BP_CH[('1','1','1')]*1.0\n",
    "print numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH=1 -->  0.152230971129   CH=2 -->  0.847769028871\n",
      "BP=1 -->  0.468551034267   BP=2 -->  0.531448965733\n"
     ]
    }
   ],
   "source": [
    "def calculate_probability(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability =  CPT_table['CPT_A'][(value_dictionary['A'],)]\\\n",
    "                    *CPT_table['CPT_G'][(value_dictionary['G'],)]\\\n",
    "                    *CPT_table['CPT_BP_G'][(value_dictionary['BP'],value_dictionary['G'])]\\\n",
    "                    *CPT_table['CPT_CH_G_A'][(value_dictionary['CH'],value_dictionary['G'],value_dictionary['A'])]\\\n",
    "                    *CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\\\n",
    "                    *CPT_table['CPT_CP_HD'][(value_dictionary['CP'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_EIA_HD'][(value_dictionary['EIA'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_ECG_HD'][(value_dictionary['ECG'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_HR_A_HD'][(value_dictionary['HR'],value_dictionary['A'],value_dictionary['HD'])]\n",
    "    return probability\n",
    "vals = {'A':'2','G':'2','CP':'4','BP':'1','CH':'1','ECG':'1','HR':'1','EIA':'1','HD':'1'}\n",
    "ch_1 = calculate_probability(vals,CPT_tables)\n",
    "vals['CH']='2'\n",
    "ch_2 = calculate_probability(vals,CPT_tables)\n",
    "print 'CH=1 --> ',ch_1/(ch_1+ch_2),'  CH=2 --> ',ch_2/(ch_1+ch_2)\n",
    "\n",
    "vals = {'A':'2','CP':'1','G':'1','BP':'1','CH':'2','ECG':'1','HR':'2','EIA':'2','HD':'1'}\n",
    "bp_1_g_1 = calculate_probability(vals,CPT_tables) \n",
    "vals['BP'],vals['G'] = '2','1'\n",
    "bp_2_g_1 = calculate_probability(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '1','2'\n",
    "bp_1_g_2 = calculate_probability(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '2','2'\n",
    "bp_2_g_2 = calculate_probability(vals,CPT_tables)\n",
    "\n",
    "bp_1 = (bp_1_g_1+bp_1_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "bp_2 = (bp_2_g_1+bp_2_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "\n",
    "print 'BP=1 --> ',bp_1,'  BP=2 --> ',bp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now By applying variable elimination rules we get the condensed form of the distribution as P(CH|G,A)*P(HD|BP,CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_probability_CH(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability =  CPT_table['CPT_CH_G_A'][(value_dictionary['CH'],value_dictionary['G'],value_dictionary['A'])]\\\n",
    "                    *CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH=1 -->  0.152230971129   CH=2 -->  0.847769028871\n"
     ]
    }
   ],
   "source": [
    "vals = {'A':'2','G':'2','CP':'4','BP':'1','CH':'1','ECG':'1','HR':'1','EIA':'1','HD':'1'}\n",
    "ch_1 = calculate_probability_CH(vals,CPT_tables)\n",
    "vals['CH']='2'\n",
    "ch_2 = calculate_probability_CH(vals,CPT_tables)\n",
    "print 'CH=1 --> ',ch_1/(ch_1+ch_2),'  CH=2 --> ',ch_2/(ch_1+ch_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are same as that of the values we calculated previously using all terms in the joint distribution.\n",
    "Now following cell will do the same reduction for b. part of question 5 where we are calculating probability of BP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_probability_BP(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability = CPT_table['CPT_G'][(value_dictionary['G'],)]\\\n",
    "                    *CPT_table['CPT_BP_G'][(value_dictionary['BP'],value_dictionary['G'])]\\\n",
    "                    *CPT_table['CPT_CH_G_A'][(value_dictionary['CH'],value_dictionary['G'],value_dictionary['A'])]\\\n",
    "                    *CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP=1 -->  0.468551034267   BP=2 -->  0.531448965733\n"
     ]
    }
   ],
   "source": [
    "vals = {'A':'2','CP':'1','G':'1','BP':'1','CH':'2','ECG':'1','HR':'2','EIA':'2','HD':'1'}\n",
    "bp_1_g_1 = calculate_probability_BP(vals,CPT_tables) \n",
    "vals['BP'],vals['G'] = '2','1'\n",
    "bp_2_g_1 = calculate_probability_BP(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '1','2'\n",
    "bp_1_g_2 = calculate_probability_BP(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '2','2'\n",
    "bp_2_g_2 = calculate_probability_BP(vals,CPT_tables)\n",
    "\n",
    "bp_1 = (bp_1_g_1+bp_1_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "bp_2 = (bp_2_g_1+bp_2_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "\n",
    "print 'BP=1 --> ',bp_1,'  BP=2 --> ',bp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "******** Following function is for calculating probability of HD using reduced distribution ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_probability_HD(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability = CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\\\n",
    "                    *CPT_table['CPT_CP_HD'][(value_dictionary['CP'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_EIA_HD'][(value_dictionary['EIA'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_ECG_HD'][(value_dictionary['ECG'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_HR_A_HD'][(value_dictionary['HR'],value_dictionary['A'],value_dictionary['HD'])]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of data-train-4.txt-- > 0.8\n",
      "\n",
      "Accuracy of data-train-1.txt-- > 0.733333333333\n",
      "\n",
      "Accuracy of data-train-3.txt-- > 0.666666666667\n",
      "\n",
      "Accuracy of data-train-5.txt-- > 0.783333333333\n",
      "\n",
      "Accuracy of data-train-2.txt-- > 0.8\n",
      "\n",
      "Mean accuracy -->  0.756666666667  Standard deviation --> 0.0512076383191\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = {}\n",
    "for i in range(5):\n",
    "    files['data-train-'+str(i+1)+'.txt']='data-test-'+str(i+1)+'.txt'\n",
    "\n",
    "accuracies = []\n",
    "for train_file in files.keys():\n",
    "    df_train = pd.read_csv('../Data/'+train_file, names=data_names,dtype=\"|S5\")\n",
    "    CPT_tables = get_CPT_all(df_train)\n",
    "    df_test = pd.read_csv('../Data/'+files[train_file], names=data_names,dtype=\"|S5\")\n",
    "    target_HD = list(df_test['HD'])\n",
    "    output_HD = []\n",
    "    for index, row in df_test.iterrows():\n",
    "        vals = {}\n",
    "        for feature in data_names:\n",
    "            vals[feature] = row[feature]\n",
    "        vals['HD'] = '1'\n",
    "        hd_1 = calculate_probability_HD(vals,CPT_tables)\n",
    "        vals['HD'] = '2'\n",
    "        hd_2 = calculate_probability_HD(vals,CPT_tables)\n",
    "        p_hd_1 = hd_1/(hd_1+hd_2)\n",
    "        p_hd_2 = hd_2/(hd_1+hd_2)\n",
    "        if p_hd_1>p_hd_2:\n",
    "            output_HD.append('1')\n",
    "        else:\n",
    "            output_HD.append('2')\n",
    "    \n",
    "    N = len(target_HD)\n",
    "    matches = [i for i, j in zip(target_HD, output_HD) if i == j]\n",
    "    print 'Accuracy of '+train_file+'-- >', len(matches)*1.0/N\n",
    "    accuracies.append(len(matches)*1.0/N)\n",
    "    print ''\n",
    "\n",
    "print 'Mean accuracy --> ',np.mean(accuracies),' Standard deviation -->',np.std(accuracies)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
