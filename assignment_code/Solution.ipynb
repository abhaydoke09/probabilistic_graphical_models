{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections, numpy\n",
    "from numpy import genfromtxt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_names = ['A','G','CP','BP','CH','ECG','HR','EIA','HD']\n",
    "data_name2index = {}\n",
    "for i,val in enumerate(data_names):\n",
    "    data_name2index[val] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_names = ['A','G','CP','BP','CH','ECG','HR','EIA','HD']\n",
    "df = pd.read_csv('../Data/data-train-1.txt', names=data_names,dtype=\"|S5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_CPT(target,all_data_frame,parents=[]):\n",
    "    CPT = {}\n",
    "    if len(parents)==0:\n",
    "        #print target\n",
    "        g = all_data_frame.groupby([target])\n",
    "        #print g.groups\n",
    "        normalizer = all_data_frame.shape[0]\n",
    "        for target_value in g.groups.keys():\n",
    "            #CPT[(target_value)] = lig.groups[target_value]\n",
    "            CPT[(target_value,)] = g.groups[target_value].shape[0]*1.0/normalizer\n",
    "        return CPT\n",
    "    else:\n",
    "        g = all_data_frame.groupby(parents)\n",
    "        data_groups = g.groups.keys()\n",
    "        #print g.groups\n",
    "        for target_value in all_data_frame[target].unique():\n",
    "            #print target_value\n",
    "            for data_group in data_groups:\n",
    "                data = all_data_frame.ix[list(g.groups[data_group])]\n",
    "                cpt_key = list(data_group)\n",
    "                cpt_key.insert(0,target_value)\n",
    "                #print data[data[target]==target_value]\n",
    "                normalizer = data.shape[0]\n",
    "                #print normalizer\n",
    "                #print \"-->\",data[data[target]==target_value].shape[0],\"-->\",normalizer\n",
    "                CPT[tuple(cpt_key)] = data[data[target]==target_value].shape[0]*1.0/normalizer\n",
    "        return CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CPT_table_nales = ['CPT_A', 'CPT_G', 'CPT_CP_HD', 'CPT_BP_G', 'CPT_ECG_HD', 'CPT_HD_BP_CH', 'CPT_CH_G_A', 'CPT_EIA_HD', 'CPT_HR_A_HD']\n",
    "def get_CPT_all(df):\n",
    "    result = {}\n",
    "    result['CPT_A'] = generate_CPT('A',df)\n",
    "    result['CPT_G'] = generate_CPT('G',df)\n",
    "    result['CPT_BP_G'] = generate_CPT('BP',df,['G'])\n",
    "    result['CPT_CH_G_A'] = generate_CPT('CH',df,['G','A'])\n",
    "    result['CPT_HD_BP_CH'] = generate_CPT('HD',df,['BP','CH'])\n",
    "    result['CPT_CP_HD'] = generate_CPT('CP',df,['HD'])\n",
    "    result['CPT_EIA_HD'] = generate_CPT('EIA',df,['HD'])\n",
    "    result['CPT_ECG_HD'] = generate_CPT('ECG',df,['HD'])\n",
    "    result['CPT_HR_A_HD'] = generate_CPT('HR',df,['A','HD'])\n",
    "    #print result.keys()\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPT_A --> {('3',): 0.5390946502057613, ('1',): 0.1646090534979424, ('2',): 0.2962962962962963}\n",
      "\n",
      "CPT_G --> {('1',): 0.32510288065843623, ('2',): 0.6748971193415638}\n",
      "\n",
      "CPT_CP_HD --> {('1', '1'): 0.11538461538461539, ('2', '2'): 0.061946902654867256, ('2', '1'): 0.23846153846153847, ('3', '1'): 0.4076923076923077, ('3', '2'): 0.13274336283185842, ('4', '1'): 0.23846153846153847, ('1', '2'): 0.061946902654867256, ('4', '2'): 0.7433628318584071}\n",
      "\n",
      "CPT_BP_G --> {('2', '1'): 0.6455696202531646, ('1', '2'): 0.4634146341463415, ('1', '1'): 0.35443037974683544, ('2', '2'): 0.5365853658536586}\n",
      "\n",
      "CPT_ECG_HD --> {('2', '1'): 0.43846153846153846, ('1', '2'): 0.3805309734513274, ('1', '1'): 0.5615384615384615, ('2', '2'): 0.6194690265486725}\n",
      "\n",
      "CPT_HD_BP_CH --> {('2', '1', '1'): 0.35, ('1', '1', '1'): 0.65, ('2', '2', '1'): 0.47619047619047616, ('1', '1', '2'): 0.5476190476190477, ('2', '2', '2'): 0.4915254237288136, ('1', '2', '2'): 0.5084745762711864, ('2', '1', '2'): 0.4523809523809524, ('1', '2', '1'): 0.5238095238095238}\n",
      "\n",
      "CPT_CH_G_A --> {('2', '1', '3'): 0.8541666666666666, ('2', '1', '1'): 0.7, ('1', '1', '1'): 0.3, ('2', '2', '1'): 0.7, ('1', '2', '3'): 0.1566265060240964, ('2', '2', '3'): 0.8433734939759037, ('1', '1', '2'): 0.09523809523809523, ('2', '2', '2'): 0.8627450980392157, ('1', '2', '2'): 0.13725490196078433, ('1', '1', '3'): 0.14583333333333334, ('2', '1', '2'): 0.9047619047619048, ('1', '2', '1'): 0.3}\n",
      "\n",
      "CPT_EIA_HD --> {('2', '1'): 0.16153846153846155, ('1', '2'): 0.4690265486725664, ('1', '1'): 0.8384615384615385, ('2', '2'): 0.5309734513274337}\n",
      "\n",
      "CPT_HR_A_HD --> {('2', '3', '1'): 0.6792452830188679, ('2', '1', '1'): 0.9310344827586207, ('1', '1', '1'): 0.06896551724137931, ('1', '3', '1'): 0.32075471698113206, ('2', '2', '1'): 0.8541666666666666, ('1', '1', '2'): 0.5454545454545454, ('2', '2', '2'): 0.4583333333333333, ('1', '2', '2'): 0.5416666666666666, ('2', '3', '2'): 0.3974358974358974, ('2', '1', '2'): 0.45454545454545453, ('1', '2', '1'): 0.14583333333333334, ('1', '3', '2'): 0.6025641025641025}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CPT_tables = get_CPT_all(df)\n",
    "for table_name in CPT_table_names:\n",
    "    print table_name,'-->',CPT_tables[table_name]\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A) -->  {('3',): 0.5390946502057613, ('1',): 0.1646090534979424, ('2',): 0.2962962962962963} \n",
      "\n",
      "P(BP|G) -->  {('2', '1'): 0.6455696202531646, ('1', '2'): 0.4634146341463415, ('1', '1'): 0.35443037974683544, ('2', '2'): 0.5365853658536586} \n",
      "\n",
      "P(HD|BP,CH) -->  {('2', '1', '1'): 0.35, ('1', '1', '1'): 0.65, ('2', '2', '1'): 0.47619047619047616, ('1', '1', '2'): 0.5476190476190477, ('2', '2', '2'): 0.4915254237288136, ('1', '2', '2'): 0.5084745762711864, ('2', '1', '2'): 0.4523809523809524, ('1', '2', '1'): 0.5238095238095238} \n",
      "\n",
      "P(HR|A,HD) -->  {('2', '3', '1'): 0.6792452830188679, ('2', '1', '1'): 0.9310344827586207, ('1', '1', '1'): 0.06896551724137931, ('1', '3', '1'): 0.32075471698113206, ('2', '2', '1'): 0.8541666666666666, ('1', '1', '2'): 0.5454545454545454, ('2', '2', '2'): 0.4583333333333333, ('1', '2', '2'): 0.5416666666666666, ('2', '3', '2'): 0.3974358974358974, ('2', '1', '2'): 0.45454545454545453, ('1', '2', '1'): 0.14583333333333334, ('1', '3', '2'): 0.6025641025641025} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'P(A) --> ',CPT_tables['CPT_A'],'\\n'\n",
    "print 'P(BP|G) --> ',CPT_tables['CPT_BP_G'],'\\n'\n",
    "print 'P(HD|BP,CH) --> ',CPT_tables['CPT_HD_BP_CH'],'\\n'\n",
    "print 'P(HR|A,HD) --> ',CPT_tables['CPT_HR_A_HD'],'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847769028871\n",
      "0.152230971129\n"
     ]
    }
   ],
   "source": [
    "#P(CH|A = 2, G = M, CP = None, BP = L, ECG = Normal, HR = L, EIA = No, HD = No)\n",
    "denominator = CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('1','2','2')]*CPT_HD_BP_CH[('1','1','1')]\\\n",
    "            + CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('2','2','2')]*CPT_HD_BP_CH[('1','1','2')]\n",
    "numerator = CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('2','2','2')]*CPT_HD_BP_CH[('1','1','2')]*1.0\n",
    "print numerator/denominator\n",
    "\n",
    "numerator = CPT_A[('2',)]*CPT_G[('2',)]*CPT_BP_G[('1','2')]*CPT_CP_HD[('4','1')]*CPT_EIA_HD[('1','1')]*\\\n",
    "            CPT_ECG_HD[('1','1')]*CPT_HR_A_HD[('1','2','1')]*CPT_CH_G_A[('1','2','2')]*CPT_HD_BP_CH[('1','1','1')]*1.0\n",
    "print numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH=1 -->  0.158839664201   CH=2 -->  0.841160335799\n",
      "BP=1 -->  0.445071890083   BP=2 -->  0.554928109917\n"
     ]
    }
   ],
   "source": [
    "def calculate_probability(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability =  CPT_table['CPT_A'][(value_dictionary['A'],)]\\\n",
    "                    *CPT_table['CPT_G'][(value_dictionary['G'],)]\\\n",
    "                    *CPT_table['CPT_BP_G'][(value_dictionary['BP'],value_dictionary['G'])]\\\n",
    "                    *CPT_table['CPT_CH_G_A'][(value_dictionary['CH'],value_dictionary['G'],value_dictionary['A'])]\\\n",
    "                    *CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\\\n",
    "                    *CPT_table['CPT_CP_HD'][(value_dictionary['CP'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_EIA_HD'][(value_dictionary['EIA'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_ECG_HD'][(value_dictionary['ECG'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_HR_A_HD'][(value_dictionary['HR'],value_dictionary['A'],value_dictionary['HD'])]\n",
    "    return probability\n",
    "vals = {'A':'2','G':'2','CP':'4','BP':'1','CH':'1','ECG':'1','HR':'1','EIA':'1','HD':'1'}\n",
    "ch_1 = calculate_probability(vals,CPT_tables)\n",
    "vals['CH']='2'\n",
    "ch_2 = calculate_probability(vals,CPT_tables)\n",
    "print 'CH=1 --> ',ch_1/(ch_1+ch_2),'  CH=2 --> ',ch_2/(ch_1+ch_2)\n",
    "\n",
    "vals = {'A':'2','CP':'1','G':'1','BP':'1','CH':'2','ECG':'1','HR':'2','EIA':'2','HD':'1'}\n",
    "bp_1_g_1 = calculate_probability(vals,CPT_tables) \n",
    "vals['BP'],vals['G'] = '2','1'\n",
    "bp_2_g_1 = calculate_probability(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '1','2'\n",
    "bp_1_g_2 = calculate_probability(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '2','2'\n",
    "bp_2_g_2 = calculate_probability(vals,CPT_tables)\n",
    "\n",
    "bp_1 = (bp_1_g_1+bp_1_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "bp_2 = (bp_2_g_1+bp_2_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "\n",
    "print 'BP=1 --> ',bp_1,'  BP=2 --> ',bp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now By applying variable elimination rules we get the condensed form of the distribution as P(CH|G,A)*P(HD|BP,CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_probability_CH(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability =  CPT_table['CPT_CH_G_A'][(value_dictionary['CH'],value_dictionary['G'],value_dictionary['A'])]\\\n",
    "                    *CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH=1 -->  0.158839664201   CH=2 -->  0.841160335799\n"
     ]
    }
   ],
   "source": [
    "vals = {'A':'2','G':'2','CP':'4','BP':'1','CH':'1','ECG':'1','HR':'1','EIA':'1','HD':'1'}\n",
    "ch_1 = calculate_probability_CH(vals,CPT_tables)\n",
    "vals['CH']='2'\n",
    "ch_2 = calculate_probability_CH(vals,CPT_tables)\n",
    "print 'CH=1 --> ',ch_1/(ch_1+ch_2),'  CH=2 --> ',ch_2/(ch_1+ch_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are same as that of the values we calculated previously using all terms in the joint distribution.\n",
    "Now following cell will do the same reduction for b. part of question 5 where we are calculating probability of BP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_probability_BP(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability = CPT_table['CPT_G'][(value_dictionary['G'],)]\\\n",
    "                    *CPT_table['CPT_BP_G'][(value_dictionary['BP'],value_dictionary['G'])]\\\n",
    "                    *CPT_table['CPT_CH_G_A'][(value_dictionary['CH'],value_dictionary['G'],value_dictionary['A'])]\\\n",
    "                    *CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP=1 -->  0.445071890083   BP=2 -->  0.554928109917\n"
     ]
    }
   ],
   "source": [
    "vals = {'A':'2','CP':'1','G':'1','BP':'1','CH':'2','ECG':'1','HR':'2','EIA':'2','HD':'1'}\n",
    "bp_1_g_1 = calculate_probability_BP(vals,CPT_tables) \n",
    "vals['BP'],vals['G'] = '2','1'\n",
    "bp_2_g_1 = calculate_probability_BP(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '1','2'\n",
    "bp_1_g_2 = calculate_probability_BP(vals,CPT_tables)\n",
    "vals['BP'],vals['G'] = '2','2'\n",
    "bp_2_g_2 = calculate_probability_BP(vals,CPT_tables)\n",
    "\n",
    "bp_1 = (bp_1_g_1+bp_1_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "bp_2 = (bp_2_g_1+bp_2_g_2)/(bp_1_g_1+bp_1_g_2+bp_2_g_1+bp_2_g_2)\n",
    "\n",
    "print 'BP=1 --> ',bp_1,'  BP=2 --> ',bp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "******** Following function is for calculating probability of HD using reduced distribution ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_probability_HD(value_dictionary,CPT_table):\n",
    "    #print value_dictionary,'\\n*******\\n',CPT_table\n",
    "    probability = CPT_table['CPT_HD_BP_CH'][(value_dictionary['HD'],value_dictionary['BP'],value_dictionary['CH'])]\\\n",
    "                    *CPT_table['CPT_CP_HD'][(value_dictionary['CP'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_EIA_HD'][(value_dictionary['EIA'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_ECG_HD'][(value_dictionary['ECG'],value_dictionary['HD'])]\\\n",
    "                    *CPT_table['CPT_HR_A_HD'][(value_dictionary['HR'],value_dictionary['A'],value_dictionary['HD'])]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of data-test-4.txt-- > 0.8\n",
      "\n",
      "Accuracy of data-test-1.txt-- > 0.733333333333\n",
      "\n",
      "Accuracy of data-test-3.txt-- > 0.666666666667\n",
      "\n",
      "Accuracy of data-test-5.txt-- > 0.783333333333\n",
      "\n",
      "Accuracy of data-test-2.txt-- > 0.8\n",
      "\n",
      "Mean accuracy -->  0.756666666667  Standard deviation --> 0.0512076383191\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = {}\n",
    "for i in range(5):\n",
    "    files['data-train-'+str(i+1)+'.txt']='data-test-'+str(i+1)+'.txt'\n",
    "\n",
    "accuracies = []\n",
    "for train_file in files.keys():\n",
    "    df_train = pd.read_csv('../Data/'+train_file, names=data_names,dtype=\"|S5\")\n",
    "    CPT_tables = get_CPT_all(df_train)\n",
    "    df_test = pd.read_csv('../Data/'+files[train_file], names=data_names,dtype=\"|S5\")\n",
    "    target_HD = list(df_test['HD'])\n",
    "    output_HD = []\n",
    "    for index, row in df_test.iterrows():\n",
    "        vals = {}\n",
    "        for feature in data_names:\n",
    "            vals[feature] = row[feature]\n",
    "        vals['HD'] = '1'\n",
    "        hd_1 = calculate_probability_HD(vals,CPT_tables)\n",
    "        vals['HD'] = '2'\n",
    "        hd_2 = calculate_probability_HD(vals,CPT_tables)\n",
    "        p_hd_1 = hd_1/(hd_1+hd_2)\n",
    "        p_hd_2 = hd_2/(hd_1+hd_2)\n",
    "        if p_hd_1>p_hd_2:\n",
    "            output_HD.append('1')\n",
    "        else:\n",
    "            output_HD.append('2')\n",
    "    \n",
    "    N = len(target_HD)\n",
    "    matches = [i for i, j in zip(target_HD, output_HD) if i == j]\n",
    "    print 'Accuracy of '+files[train_file]+'-- >', len(matches)*1.0/N\n",
    "    accuracies.append(len(matches)*1.0/N)\n",
    "    print ''\n",
    "\n",
    "print 'Mean accuracy --> ',np.mean(accuracies),' Standard deviation -->',np.std(accuracies)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
